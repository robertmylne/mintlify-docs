---
title: 'Rate Limits'
description: 'Understanding API rate limits and how to handle them in your applications'
---

## Overview

The API implements rate limiting to ensure fair usage and maintain service quality for all users. The current rate limit is **60 requests per minute** per API key.

## Rate Limit Details

### Current Limits

| Limit Type | Requests | Time Window | Scope |
|------------|----------|-------------|-------|
| Standard | 60 | 1 minute | Per API key |

### Reset Behavior

Rate limits reset at the beginning of each time window:
- **60 requests per minute**: Resets every minute at the top of the minute (e.g., 12:00:00, 12:01:00, 12:02:00)

## Rate Limit Headers

Every API response includes headers that show your current rate limit status:

```http
HTTP/1.1 200 OK
X-RateLimit-Limit: 60
X-RateLimit-Remaining: 45
X-RateLimit-Reset: 1640995260
X-RateLimit-Window: 60
```

### Header Descriptions

| Header | Description |
|--------|-------------|
| `X-RateLimit-Limit` | Maximum requests allowed in the time window |
| `X-RateLimit-Remaining` | Requests remaining in current window |
| `X-RateLimit-Reset` | Unix timestamp when the rate limit resets |
| `X-RateLimit-Window` | Rate limit window duration in seconds |

## Rate Limit Exceeded Response

When you exceed the rate limit, you'll receive a `429 Too Many Requests` response:

```json
{
  "error": {
    "code": "rate_limit_exceeded",
    "message": "Rate limit exceeded. Please try again later.",
    "details": {
      "limit": 60,
      "window": "1 minute",
      "retry_after": 30
    }
  }
}
```

The response includes a `Retry-After` header indicating when you can make your next request:

```http
HTTP/1.1 429 Too Many Requests
Retry-After: 30
X-RateLimit-Limit: 60
X-RateLimit-Remaining: 0
X-RateLimit-Reset: 1640995260
```

## Handling Rate Limits

### Basic Rate Limit Handling

```javascript
async function makeAPIRequest(url, options) {
  const response = await fetch(url, options);

  if (response.status === 429) {
    const retryAfter = response.headers.get('Retry-After');
    console.log(`Rate limited. Retry after ${retryAfter} seconds`);

    // Wait before retrying
    await new Promise(resolve => setTimeout(resolve, retryAfter * 1000));
    return makeAPIRequest(url, options); // Retry the request
  }

  return response;
}
```

### Advanced Rate Limit Management

```javascript
class RateLimitManager {
  constructor() {
    this.queue = [];
    this.processing = false;
    this.remainingRequests = 60;
    this.resetTime = null;
  }

  async makeRequest(url, options) {
    return new Promise((resolve, reject) => {
      this.queue.push({ url, options, resolve, reject });
      this.processQueue();
    });
  }

  async processQueue() {
    if (this.processing || this.queue.length === 0) return;

    this.processing = true;

    while (this.queue.length > 0) {
      // Check if we need to wait for rate limit reset
      if (this.remainingRequests <= 0) {
        const waitTime = this.resetTime - Date.now();
        if (waitTime > 0) {
          console.log(`Waiting ${waitTime}ms for rate limit reset`);
          await new Promise(resolve => setTimeout(resolve, waitTime));
        }
      }

      const { url, options, resolve, reject } = this.queue.shift();

      try {
        const response = await fetch(url, options);

        // Update rate limit tracking
        this.remainingRequests = parseInt(response.headers.get('X-RateLimit-Remaining')) || 0;
        this.resetTime = parseInt(response.headers.get('X-RateLimit-Reset')) * 1000;

        if (response.status === 429) {
          const retryAfter = response.headers.get('Retry-After');
          await new Promise(resolve => setTimeout(resolve, retryAfter * 1000));
          this.queue.unshift({ url, options, resolve, reject }); // Put back at front
          continue;
        }

        resolve(response);
      } catch (error) {
        reject(error);
      }
    }

    this.processing = false;
  }
}

// Usage
const rateLimiter = new RateLimitManager();
const response = await rateLimiter.makeRequest('/api/v1/users', { method: 'GET' });
```

### Monitoring Rate Limits

```javascript
function logRateLimitStatus(response) {
  const limit = response.headers.get('X-RateLimit-Limit');
  const remaining = response.headers.get('X-RateLimit-Remaining');
  const reset = response.headers.get('X-RateLimit-Reset');

  console.log(`Rate Limit Status: ${remaining}/${limit} requests remaining`);
  console.log(`Resets at: ${new Date(reset * 1000).toISOString()}`);

  // Warn when approaching limit
  if (remaining < 10) {
    console.warn('⚠️  Approaching rate limit!');
  }
}

// Use with every API call
const response = await fetch('/api/v1/users');
logRateLimitStatus(response);
```

## Best Practices

### Optimize Request Patterns

- **Batch operations** when possible to reduce total requests
- **Cache responses** to avoid repeated requests for the same data
- **Use webhooks** instead of polling when available
- **Implement pagination** efficiently to avoid large single requests

### Implement Backoff Strategies

```javascript
async function exponentialBackoff(fn, maxRetries = 3) {
  for (let attempt = 1; attempt <= maxRetries; attempt++) {
    try {
      const response = await fn();

      if (response.status !== 429) {
        return response;
      }

      if (attempt === maxRetries) {
        throw new Error('Max retries exceeded');
      }

      // Exponential backoff: 1s, 2s, 4s
      const delay = Math.pow(2, attempt - 1) * 1000;
      console.log(`Rate limited. Retrying in ${delay}ms (attempt ${attempt})`);
      await new Promise(resolve => setTimeout(resolve, delay));

    } catch (error) {
      if (attempt === maxRetries) throw error;
    }
  }
}

// Usage
const response = await exponentialBackoff(() =>
  fetch('/api/v1/users', { headers: { 'Authorization': 'Bearer token' } })
);
```

### Distribute Load

- **Spread requests** across time rather than bursting
- **Use multiple API keys** for different services if needed
- **Implement request queuing** to smooth out traffic spikes

## Rate Limit Monitoring

### Dashboard Metrics

Monitor your rate limit usage in the dashboard:
- **Current usage** across all time windows
- **Historical patterns** to identify peak usage
- **Alerts** when approaching limits

### Programmatic Monitoring

```javascript
class RateLimitMonitor {
  constructor() {
    this.metrics = {
      totalRequests: 0,
      rateLimitHits: 0,
      averageRemaining: 0
    };
  }

  recordRequest(response) {
    this.metrics.totalRequests++;

    if (response.status === 429) {
      this.metrics.rateLimitHits++;
    }

    const remaining = parseInt(response.headers.get('X-RateLimit-Remaining'));
    this.metrics.averageRemaining =
      (this.metrics.averageRemaining + remaining) / 2;
  }

  getEfficiency() {
    return {
      hitRate: this.metrics.rateLimitHits / this.metrics.totalRequests,
      averageRemaining: this.metrics.averageRemaining
    };
  }
}
```

## Increasing Rate Limits

If you need higher rate limits for your application:

1. **Contact support** with your use case details
2. **Provide traffic patterns** and expected volumes
3. **Demonstrate good rate limit handling** in your current implementation
4. **Consider enterprise plans** for significantly higher limits

<Warning>
Consistently hitting rate limits may indicate inefficient API usage. Review your integration patterns before requesting limit increases.
</Warning>

<Tip>
Use the `X-RateLimit-Remaining` header to implement proactive rate limit management instead of waiting for 429 responses.
</Tip>